{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Rittman Analytics ltd\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "mR2-yJDPyVFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profit & Loss Report Chatbot (RAG + SQL Agent)\n",
        "\n",
        "## Overview\n",
        "\n",
        "This Jupyter notebook implements an advanced question-answering system for Profit and Loss (P&L) data analysis. It leverages Large Language Models (LLMs), Google BigQuery Vector Storage, and LangChain to provide intelligent, context-aware responses to financial queries.\n",
        "\n",
        "## Key Technologies\n",
        "\n",
        "- **Large Language Models (LLMs)**: Powers natural language understanding and generation.\n",
        "- **Google BigQuery Vector Storage**: Stores and retrieves pre-analyzed financial data as vectors.\n",
        "- **LangChain**: Orchestrates the interaction between LLMs, vector storage, and SQL databases.\n",
        "- **SQL Agent**: Dynamically generates and executes SQL queries based on natural language questions.\n",
        "\n",
        "## Core Functionality\n",
        "\n",
        "### 1. Vector Store Retrieval\n",
        "\n",
        "- Utilizes `BigQueryVectorStore` from LangChain for efficient similarity search.\n",
        "- Pre-analyzed financial reports are stored as vector embeddings.\n",
        "- `VertexAIEmbeddings` is used to generate embeddings for queries and documents.\n",
        "\n",
        "### 2. LLM-Powered Decision Making\n",
        "\n",
        "- `should_query_vector_store()` function uses an LLM to decide whether to query the vector store or use SQL.\n",
        "- LLM considers the question content, time frame, and available data to make this decision.\n",
        "\n",
        "### 3. Dynamic SQL Query Generation\n",
        "\n",
        "- Employs LangChain's SQL Agent to convert natural language questions into SQL queries.\n",
        "- `create_sql_agent()` sets up an agent with access to database schema and query execution capabilities.\n",
        "- `SQLDatabaseToolkit` provides the agent with necessary tools for SQL operations.\n",
        "\n",
        "### 4. Intelligent Question Processing\n",
        "\n",
        "- `extract_date_from_question()` uses regex and LLM capabilities to understand temporal aspects of queries.\n",
        "- `find_matching_values()` identifies relevant financial categories and groups mentioned in the question.\n",
        "\n",
        "### 5. Answer Generation and Evaluation\n",
        "\n",
        "- Combines information from vector store and SQL queries to generate comprehensive answers.\n",
        "- `evaluate_answer_relevance()` uses an LLM to assess the relevance and quality of the generated answer.\n",
        "\n",
        "## LangChain Components Used\n",
        "\n",
        "- `ChatOpenAI`: Interface for the LLM (e.g., GPT-4).\n",
        "- `ConversationChain`: Manages conversation context.\n",
        "- `LLMChain`: Executes specific LLM tasks like decision making and evaluation.\n",
        "- `PromptTemplate`: Structures prompts for consistent LLM interactions.\n",
        "- `SQLDatabase`: Provides an interface to the SQL database.\n",
        "- `BigQueryVectorStore`: Manages vector storage and retrieval in BigQuery.\n",
        "\n",
        "## Setup and Configuration\n",
        "\n",
        "1. Install required packages:\n",
        "   ```\n",
        "   pip install langchain langchain-google-vertexai langchain-google-community google-cloud-bigquery sqlalchemy\n",
        "   ```\n",
        "\n",
        "2. Set up Google Cloud credentials and BigQuery access.\n",
        "\n",
        "3. Configure the notebook variables:\n",
        "   - `project`: Your Google Cloud project ID\n",
        "   - `dataset`: BigQuery dataset name\n",
        "   - `service_account_file`: Path to your Google Cloud service account key\n",
        "\n",
        "4. Set up your OpenAI API key as an environment variable.\n",
        "\n",
        "## Usage\n",
        "\n",
        "1. Initialize the notebook components:\n",
        "   ```python\n",
        "   main(reload_vector_storage=True)\n",
        "   ```\n",
        "\n",
        "2. Start the interactive query session:\n",
        "   ```python\n",
        "   question = \"What was our revenue in May 2024?\"\n",
        "   response = ask_question(question)\n",
        "   print(response)\n",
        "   ```\n",
        "\n",
        "## Customization\n",
        "\n",
        "- Modify `vector_store_content_description` to match your financial data structure.\n",
        "- Adjust `extract_date_from_question()` for different date formats.\n",
        "- Customize SQL views in `determine_view()` to match your database schema.\n",
        "\n",
        "## Advanced Features\n",
        "\n",
        "- **Hybrid Retrieval**: Combines vector similarity search with SQL queries for comprehensive answers.\n",
        "- **Dynamic Time Awareness**: Automatically adjusts queries based on the time frame mentioned in the question.\n",
        "- **Relevance Scoring**: Uses LLM to evaluate the quality and relevance of generated answers."
      ],
      "metadata": {
        "id": "ydLEIo96yEHb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bs4 langchain langchain-community langchain-google-community langchain_google_vertexai langchain-openai openai chromadb tiktoken tabulate sqlalchemy sqlalchemy-bigquery google-cloud-bigquery"
      ],
      "metadata": {
        "id": "Vgwq64_7G1cC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import bigquery\n",
        "from sqlalchemy import *\n",
        "from sqlalchemy.engine import create_engine\n",
        "from sqlalchemy.schema import *\n",
        "import os\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_google_community import BigQueryVectorStore\n",
        "import re\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "\n",
        "service_account_file = \"/content/ra-development-bf14f75f80cd.json\"\n",
        "project = \"ra-development\"\n",
        "dataset = \"analytics_finance_demo\"\n",
        "sqlalchemy_url = f'bigquery://{project}/{dataset}?credentials_path={service_account_file}'\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "vector_store_content_description = \"\"\"\n",
        "The vector store contains pre-created analysis with the following information:\n",
        "1. Key Metrics\n",
        "   - Revenue, Overheads, Cost of Delivery, Gross & Net Profit, Retained Earnings net amounts\n",
        "   - Account Sub-Category and Account Group net amounts\n",
        "2. Key Metrics Calculation:\n",
        "   - Month-over-month, year-to-date, and budget variance calculations\n",
        "   - Gross margin percentages\n",
        "3. Significant Transaction Identification:\n",
        "   - Transactions exceeding a certain percentage threshold of the total account group amount\n",
        "   - Cancelling transactions are identified and excluded\n",
        "   - Context for each significant transaction (new or changed from previous month)\n",
        "4. Overhead Trend Analysis:\n",
        "   - Monthly growth rates for overhead categories over the last 6 months\n",
        "   - Account groups with significant average monthly growth (> 10%)\n",
        "5. Identification of New Repeating Transactions:\n",
        "   - Transactions with the same description appearing consistently over the last 3 months\n",
        "\n",
        "The analysis covers the last three months and the current year-to-date at summary level for category, subcategory, and account group levels.\n",
        "\"\"\"\n",
        "\n",
        "# Create a BigQuery client\n",
        "client = bigquery.Client.from_service_account_json(service_account_file)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding = VertexAIEmbeddings(\n",
        "    model_name=\"textembedding-gecko@latest\",\n",
        "    project=project\n",
        ")\n",
        "\n",
        "# Initialize BigQueryVectorStore\n",
        "vector_store = BigQueryVectorStore(\n",
        "    project_id=project,\n",
        "    dataset_name=dataset,\n",
        "    table_name=\"pl_reports_vector_storage\",\n",
        "    location=\"europe-west2\",\n",
        "    embedding=embedding,\n",
        ")\n",
        "\n",
        "def load_vector_storage():\n",
        "    query = f\"\"\"\n",
        "    SELECT date_month as month, report_analysis, invoice_analysis, recurring_payments_analysis\n",
        "    FROM `{project}.{dataset}.pl_reports`\n",
        "    \"\"\"\n",
        "    df = client.query(query).to_dataframe()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        month = row['month']\n",
        "        for analysis_type in ['report_analysis', 'invoice_analysis', 'recurring_payments_analysis']:\n",
        "            text = row[analysis_type]\n",
        "            metadata = {\n",
        "                'month': month,\n",
        "                'analysis_type': analysis_type\n",
        "            }\n",
        "            vector_store.add_texts([text], metadatas=[metadata])\n",
        "\n",
        "    print(\"Vector storage loaded successfully.\")\n",
        "\n",
        "def get_available_months():\n",
        "    query = f\"\"\"\n",
        "    SELECT DISTINCT month as month\n",
        "    FROM `{project}.{dataset}.pl_reports_vector_storage`\n",
        "    ORDER BY month DESC\n",
        "    \"\"\"\n",
        "    df = client.query(query).to_dataframe()\n",
        "    return df['month'].tolist()\n",
        "\n",
        "# Add this function to determine the valid time range\n",
        "def get_valid_time_range(available_months):\n",
        "    if not available_months:\n",
        "        return None, None\n",
        "\n",
        "    latest_month = max(available_months)\n",
        "    earliest_month = min(available_months)\n",
        "\n",
        "    # Calculate the start of the year for the latest month\n",
        "    year_start = latest_month.replace(month=1, day=1)\n",
        "\n",
        "    # The valid range includes two months before the earliest available month\n",
        "    valid_start = (earliest_month - relativedelta(months=2)).replace(day=1)\n",
        "\n",
        "    return valid_start, latest_month\n",
        "\n",
        "def create_lookup_tables():\n",
        "    query = f\"\"\"\n",
        "    SELECT DISTINCT\n",
        "        account_report_group,\n",
        "        account_report_sub_category,\n",
        "        account_category\n",
        "    FROM `{project}.{dataset}.profit_and_loss_report_account_group`\n",
        "    \"\"\"\n",
        "    df = client.query(query).to_dataframe()\n",
        "\n",
        "    lookups = {\n",
        "        'group': defaultdict(list),\n",
        "        'sub_category': defaultdict(list),\n",
        "        'category': defaultdict(list)\n",
        "    }\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        group = row['account_report_group']\n",
        "        sub_category = row['account_report_sub_category']\n",
        "        category = row['account_category']\n",
        "\n",
        "        lookups['group'][group.lower()].append(group)\n",
        "        lookups['sub_category'][sub_category.lower()].append(sub_category)\n",
        "        lookups['category'][category.lower()].append(category)\n",
        "\n",
        "    return lookups\n",
        "\n",
        "lookups = create_lookup_tables()\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "db = SQLDatabase.from_uri(sqlalchemy_url)\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "conversation_chain = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    top_k=1000,\n",
        ")\n",
        "\n",
        "def find_matching_values(question, lookups):\n",
        "    words = question.lower().split()\n",
        "    matches = {\n",
        "        'group': set(),\n",
        "        'sub_category': set(),\n",
        "        'category': set()\n",
        "    }\n",
        "\n",
        "    for word in words:\n",
        "        for key in lookups:\n",
        "            if word in lookups[key]:\n",
        "                matches[key].update(lookups[key][word])\n",
        "\n",
        "    return matches\n",
        "\n",
        "def construct_filter_clause(matches):\n",
        "    clauses = []\n",
        "    for key, values in matches.items():\n",
        "        if values:\n",
        "            column = \"account_report_group\" if key == \"group\" else f\"account_{key}\"\n",
        "            quoted_values = [\"'{0}'\".format(v) for v in values]\n",
        "            clause = \"{0} IN ({1})\".format(column, \", \".join(quoted_values))\n",
        "            clauses.append(clause)\n",
        "\n",
        "    return \" AND \".join(clauses) if clauses else \"\"\n",
        "\n",
        "def determine_view(matches):\n",
        "    if matches['group']:\n",
        "        return \"profit_and_loss_report_account_group\"\n",
        "    elif matches['sub_category']:\n",
        "        return \"profit_and_loss_report_sub_categories\"\n",
        "    else:\n",
        "        return \"profit_and_loss_report_categories\"\n",
        "\n",
        "def extract_date_from_question(question):\n",
        "    # Look for year and month patterns\n",
        "    year_pattern = r'\\b(20\\d{2})\\b'\n",
        "    month_pattern = r'\\b(January|February|March|April|May|June|July|August|September|October|November|December)\\b'\n",
        "\n",
        "    year_match = re.search(year_pattern, question)\n",
        "    month_match = re.search(month_pattern, question, re.IGNORECASE)\n",
        "\n",
        "    if year_match and month_match:\n",
        "        year = year_match.group(1)\n",
        "        month = month_match.group(1).capitalize()\n",
        "        month_num = datetime.strptime(month, \"%B\").month\n",
        "        return f\"{year}-{month_num:02d}-01\"\n",
        "    elif year_match:\n",
        "        return f\"{year_match.group(1)}-01-01\"  # Default to January if only year is specified\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def strip_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def summarize_content(question, content):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"content\"],\n",
        "        template=\"\"\"Given the following question and content, provide a concise summary of the content that is directly relevant to answering the question.\n",
        "        Ignore any information that doesn't pertain to the question. All amounts should be stated in GBP (Â£).\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Content: {content}\n",
        "\n",
        "        Relevant Summary:\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    summary = chain.run(question=question, content=content)\n",
        "    return summary.strip()\n",
        "\n",
        "def should_query_vector_store(question):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"content_description\", \"valid_time_range\"],\n",
        "        template=\"\"\"Given the following question and description of the content in a vector store,\n",
        "        determine if the vector store is likely to contain information that can answer the question.\n",
        "        Consider the following:\n",
        "        1. Does the question ask about any of the key metrics or analyses mentioned in the content description?\n",
        "        2. Does the question fall within the time frame covered by the vector store? Valid time range: {valid_time_range}\n",
        "        3. Is the level of detail requested (category, subcategory, account group) available in the vector store?\n",
        "\n",
        "        Respond with 'Yes' if the vector store is likely to contain relevant information, or 'No' if it's unlikely or unclear.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Vector Store Content Description:\n",
        "        {content_description}\n",
        "\n",
        "        Decision (Yes/No):\n",
        "        Explanation:\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    response = chain.run(question=question,\n",
        "                         content_description=vector_store_content_description,\n",
        "                         valid_time_range=f\"{valid_time_range[0].strftime('%B %Y')} to {valid_time_range[1].strftime('%B %Y')}\")\n",
        "\n",
        "    print(f\"LLM Response for vector store query decision:\\n{response}\")  # Debug print\n",
        "\n",
        "    # Extract the decision from the response\n",
        "    decision_match = re.search(r'Decision \\(Yes/No\\):\\s*(Yes|No)', response, re.IGNORECASE)\n",
        "    if decision_match:\n",
        "        decision = decision_match.group(1).lower()\n",
        "        print(f\"Extracted decision: {decision}\")  # Debug print\n",
        "        return decision == 'yes'\n",
        "    else:\n",
        "        # If no clear decision is found in the expected format, look for a 'Yes' at the beginning of the response\n",
        "        if response.strip().lower().startswith('yes'):\n",
        "            print(\"'Yes' found at the start of the response. Using vector store.\")  # Debug print\n",
        "            return True\n",
        "        else:\n",
        "            print(\"No clear 'Yes' decision found in LLM response. Defaulting to not using vector store.\")  # Debug print\n",
        "            return False\n",
        "\n",
        "def evaluate_answer_relevance(question, answer):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"answer\"],\n",
        "        template=\"\"\"Given the following question and answer, evaluate how well the answer addresses the question.\n",
        "        Provide a relevance score as a percentage and a brief explanation.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Answer: {answer}\n",
        "\n",
        "        Relevance Score (0-100%):\n",
        "        Explanation:\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    response = chain.run(question=question, answer=answer)\n",
        "    return response\n",
        "\n",
        "def ask_question(question):\n",
        "    extracted_date = extract_date_from_question(question)\n",
        "\n",
        "    if should_query_vector_store(question):\n",
        "        month = extracted_date if extracted_date else extract_month_from_question(question)\n",
        "        filter_dict = {\"month\": month} if month else {}\n",
        "        relevant_docs = vector_store.similarity_search(question, k=1, filter=filter_dict)\n",
        "\n",
        "        if relevant_docs:\n",
        "            pre_created_answer = relevant_docs[0].page_content\n",
        "            stripped_answer = strip_html(pre_created_answer)\n",
        "            summarized_answer = summarize_content(question, stripped_answer)\n",
        "            answer = f\"Based on the pre-created analysis: {summarized_answer}\"\n",
        "        else:\n",
        "            answer = \"No relevant pre-created analysis found. Falling back to SQL query.\"\n",
        "    else:\n",
        "        answer = \"The question cannot be answered by pre-created analysis. Using SQL query.\"\n",
        "\n",
        "    if \"Using SQL query\" in answer:\n",
        "        # Use the existing SQL query functionality\n",
        "        matches = find_matching_values(question, lookups)\n",
        "        filter_clause = construct_filter_clause(matches)\n",
        "        view_name = determine_view(matches)\n",
        "\n",
        "        if extracted_date:\n",
        "            date_filter = f\"date_trunc(date_month, MONTH) = DATE('{extracted_date}')\"\n",
        "        else:\n",
        "            date_filter = \"\"\n",
        "\n",
        "        filter_clause = f\"{date_filter} AND {filter_clause}\" if filter_clause else date_filter\n",
        "\n",
        "        instruction = f\"\"\"You are a knowledgeable finance data analyst working for Rittman Analytics.\n",
        "        Use the `{project}.{dataset}.{view_name}` view to answer this question.\n",
        "        Use the following SQL filter clause in your query: {filter_clause}\n",
        "        Please construct and execute a SQL query to answer the question, making sure to include the filter clause.\n",
        "        Do not include markdown-style triple backticks in the SQL you generate and try to use or validate.\n",
        "        Question is: {question}\n",
        "        \"\"\"\n",
        "\n",
        "        answer = agent_executor.run(instruction)\n",
        "\n",
        "    relevance_evaluation = evaluate_answer_relevance(question, answer)\n",
        "\n",
        "    return f\"{answer}\\n\\nRelevance Evaluation:\\n{relevance_evaluation}\"\n",
        "\n",
        "def main(reload_vector_storage=False):\n",
        "    global valid_time_range, vector_store_content_description\n",
        "\n",
        "    if reload_vector_storage:\n",
        "        load_vector_storage()\n",
        "\n",
        "    available_months = get_available_months()\n",
        "    valid_time_range = get_valid_time_range(available_months)\n",
        "\n",
        "    # Update the vector_store_content_description with the actual time range\n",
        "    vector_store_content_description += f\"\"\"\n",
        "    The analysis covers the period from {valid_time_range[0].strftime('%B %Y')} to {valid_time_range[1].strftime('%B %Y')}.\n",
        "    For each month in this range, the analysis includes data for that month, comparisons to the two previous months, and year-to-date figures.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Hi! Ask me a question about our company's profit and loss data\")\n",
        "    while True:\n",
        "        question = input()\n",
        "        if question.lower() == 'quit':\n",
        "            break\n",
        "        else:\n",
        "            response = ask_question(question)\n",
        "            print(f\"{response}\\n\")\n",
        "            print(\"Is there anything else I can answer for you? Or type QUIT to exit\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(reload_vector_storage=False)  # Set to True to reload vector storage"
      ],
      "metadata": {
        "id": "e8RVylqGG2Gw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sJxTdIJpdhGU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}