{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": [],
      "name": "profit_and_loss_self_learning_chatbot.py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2024 Rittman Analytics ltd\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "id": "6QHj_OzW_7pA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Profit & Loss Report QA Chatbot using LLMs, LangChain and BigQuery Vector Store\n",
        "\n",
        "This notebook implements a question-answering system leveraging Large Language Models (LLMs), Langchain, and a vector store in BigQuery to analyze profit and loss (P&L) data. The system allows users to ask natural language questions about the P&L data and receive relevant answers.\n",
        "\n",
        "### System Architecture\n",
        "\n",
        "The system consists of several key components:\n",
        "\n",
        "1. **Data Source (BigQuery):** The P&L data resides in BigQuery, organized into tables like `pl_reports`, `profit_and_loss_report_account_group`, etc. Pre-computed analysis is stored in `pl_reports_vector_storage`.\n",
        "\n",
        "2. **Vector Store (BigQuery):** A BigQueryVectorStore is used to store embeddings of pre-created P&L analysis texts. This allows for efficient similarity search to quickly find relevant context for user questions. The table `pl_reports_vector_storage` holds these embeddings. A separate vector store, `successful_qa_pairs`, is used to store successful question-answer pairs for learning and improving the system's performance.\n",
        "\n",
        "3. **LLM (OpenAI's GPT-4):** The core intelligence is provided by OpenAI's GPT-4, acting as the question answering engine and providing natural language processing capabilities.\n",
        "\n",
        "4. **Langchain:** Langchain orchestrates the interaction between the different components. It manages the agent, memory, chains, and toolkits to provide a cohesive and efficient workflow.\n",
        "\n",
        "5. **SQL Agent (Langchain):** An SQL agent is used to directly query BigQuery when the vector store does not contain sufficient information to answer a question.\n",
        "\n",
        "6. **Embedding Model (Vertex AI):** `textembedding-gecko@latest` from Google Vertex AI creates vector embeddings of text data, enabling semantic search within the vector store.\n",
        "\n",
        "### Question Answering Workflow\n",
        "\n",
        "The process of answering a question follows these steps:\n",
        "\n",
        "1. **Question Analysis:** The user enters a natural language question.\n",
        "\n",
        "2. **Vector Store Query (First Attempt):** The system determines whether the question can be answered using the pre-created analysis stored in the `pl_reports_vector_storage` vector store. This is determined by a prompt sent to the LLM, evaluating if the question aligns with the types of analyses performed and the available time range. If deemed suitable, a similarity search is performed to retrieve the most relevant document(s).\n",
        "\n",
        "3. **Pre-created Answer Summarization:** If relevant documents are found, their content is extracted, stripped of HTML tags, and summarized using the LLM to focus only on information relevant to the question. This avoids providing irrelevant information from the original analysis.\n",
        "\n",
        "4. **SQL Query (Fallback):** If the vector store query does not yield satisfactory results or is deemed unsuitable, the system uses the Langchain SQL agent. This component uses the LLM to:\n",
        "- Analyze the question to identify relevant financial terms and entities.\n",
        "- Translate these terms into a suitable SQL `WHERE` clause to filter the data.\n",
        "- Construct a SQL query to the appropriate BigQuery view (`profit_and_loss_report_account_group_xa`, `profit_and_loss_report_sub_categories_xa`, or `profit_and_loss_report_categories_xa` depending on the question context). The view selection is determined by analysis of the question.\n",
        "- Execute the query in BigQuery and format the results into a readable answer.\n",
        "\n",
        "5. **Answer Relevance Evaluation:** The generated answer (whether from the vector store or SQL query) is evaluated by the LLM to assess its relevance to the original question and provides a relevance score and explanation.\n",
        "\n",
        "6. **Feedback and Learning:** The user provides feedback on the answer. This feedback is used to improve the question for subsequent iterations, aiming to refine the answer. Successful question-answer pairs are stored in the `successful_qa_pairs` vector store, improving future responses.\n",
        "\n",
        "7. **Iterative Refinement (Optional):** The system allows for iterative refinement based on user feedback. The LLM is used to reformulate the question in response to feedback, repeating the process for `max_iterations` (default 3).\n",
        "\n",
        "### Key Functions\n",
        "\n",
        "* **`ask_question(question, context=\"\")`:** The main function for answering questions. It orchestrates the vector store search and SQL query processes.\n",
        "* **`should_query_vector_store(question)`:** Determines if a vector store search is likely to provide a relevant answer.\n",
        "* **`summarize_content(question, content)`:** Summarizes the retrieved vector store content to focus only on relevant information.\n",
        "* **`find_matching_values(question, lookups)`:** Extracts relevant financial entities from the question to construct the SQL `WHERE` clause.\n",
        "* **`construct_filter_clause(matches)`:** Creates the SQL `WHERE` clause using extracted entities and time periods.\n",
        "* **`determine_view(matches)`:** Selects the appropriate BigQuery view based on the question's context.\n",
        "* **`extract_time_periods(question)`:** Extracts time periods from the question for filtering.\n",
        "* **`get_similar_qa(question)`:** Retrieves similar Q&A pairs from the `successful_qa_pairs` vector store for context.\n",
        "* **`ask_question_with_feedback_and_learning(question)`:** Handles user feedback and iterative refinement.\n",
        "* **`store_successful_qa(question, answer)`:** Stores successful Q&A pairs in the `successful_qa_pairs` vector store.\n",
        "\n",
        "\n",
        "### Setup and Dependencies\n",
        "\n",
        "The notebook requires several Python packages, listed at the beginning of the file. Ensure you have installed them before running the code. You will also need to configure:\n",
        "\n",
        "* A service account key file (`service_account_file`) with access to your BigQuery project.\n",
        "* An OpenAI API key (`OPENAI_API_KEY`).\n",
        "* The correct BigQuery project ID, dataset name, and table names."
      ],
      "metadata": {
        "id": "hOERDTsyVB8l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install bs4 langchain langchain-community langchain-google-community langchain_google_vertexai langchain-openai openai chromadb tiktoken tabulate sqlalchemy sqlalchemy-bigquery google-cloud-bigquery"
      ],
      "metadata": {
        "id": "qGLdYxA3Wq6-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import bigquery\n",
        "from google.api_core import exceptions\n",
        "from sqlalchemy import *\n",
        "from sqlalchemy.engine import create_engine\n",
        "from sqlalchemy.schema import *\n",
        "from langchain.agents import create_sql_agent\n",
        "from langchain.agents.agent_toolkits import SQLDatabaseToolkit\n",
        "from langchain.sql_database import SQLDatabase\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.agents import AgentExecutor\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain, LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_google_community import BigQueryVectorStore\n",
        "import re\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from dateutil.relativedelta import relativedelta\n",
        "from langchain.docstore.document import Document\n",
        "from dateutil import parser\n",
        "import calendar\n",
        "\n"
      ],
      "metadata": {
        "id": "1UDkrP8EW2_i",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1727719008391,
          "user_tz": -60,
          "elapsed": 149,
          "user": {
            "displayName": "",
            "userId": ""
          }
        }
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "service_account_file = \"/content/ra-development-d027d9a2dd60.json\"\n",
        "project = \"ra-development\"\n",
        "dataset = \"analytics_finance_demo\"\n",
        "location = \"europe-west2\"\n",
        "sqlalchemy_url = f'bigquery://{project}/{dataset}?credentials_path={service_account_file}'\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
        "\n",
        "vector_store_content_description = \"\"\"\n",
        "The vector store contains pre-created analysis with the following information:\n",
        "1. Key Metrics\n",
        "   - Revenue, Overheads, Cost of Delivery, Gross & Net Profit, Retained Earnings net amounts\n",
        "   - Account Sub-Category and Account Group net amounts\n",
        "2. Key Metrics Calculation:\n",
        "   - Month-over-month, year-to-date, and budget variance calculations\n",
        "   - Gross margin percentages\n",
        "3. Significant Transaction Identification:\n",
        "   - Transactions exceeding a certain percentage threshold of the total account group amount\n",
        "   - Cancelling transactions are identified and excluded\n",
        "   - Context for each significant transaction (new or changed from previous month)\n",
        "4. Overhead Trend Analysis:\n",
        "   - Monthly growth rates for overhead categories over the last 6 months\n",
        "   - Account groups with significant average monthly growth (> 10%)\n",
        "5. Identification of New Repeating (Recurring) Transactions:\n",
        "   - Transactions with the same description appearing consistently over the last 3 months\n",
        "\n",
        "The analysis covers the last three months and the current year-to-date at summary level for category, subcategory, and account group levels.\n",
        "\"\"\"\n",
        "\n",
        "# Create a BigQuery client\n",
        "client = bigquery.Client.from_service_account_json(service_account_file)\n",
        "\n",
        "# Initialize embedding model\n",
        "embedding_model = VertexAIEmbeddings(\n",
        "    model_name=\"textembedding-gecko@latest\",\n",
        "    project=project\n",
        ")\n",
        "\n",
        "# Initialize BigQueryVectorStore containing P&L report analysis texts\n",
        "vector_store = BigQueryVectorStore(\n",
        "    project_id=project,\n",
        "    dataset_name=dataset,\n",
        "    table_name=\"pl_reports_vector_storage\",\n",
        "    location=location,\n",
        "    embedding=embedding_model,\n",
        ")\n",
        "\n",
        "def create_successful_qa_table():\n",
        "    table_id = f\"{project}.{dataset}.successful_qa_pairs\"  # Correct table ID\n",
        "\n",
        "    schema = [\n",
        "        bigquery.SchemaField(\"content\", \"STRING\", mode=\"REQUIRED\"),\n",
        "        bigquery.SchemaField(\"embedding\", \"FLOAT64\", mode=\"REPEATED\"),\n",
        "        bigquery.SchemaField(\"id\", \"STRING\", mode=\"REQUIRED\"),\n",
        "    ]\n",
        "\n",
        "    table = bigquery.Table(table_id, schema=schema)\n",
        "    table.clustering_fields = [\"id\"]\n",
        "\n",
        "    try:\n",
        "        table = client.create_table(table)  # Use the client from outside\n",
        "        print(f\"Created table {table.project}.{table.dataset_id}.{table.table_id}\")\n",
        "    except exceptions.Conflict:\n",
        "        print(f\"Table  already exists.\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while creating the table: {str(e)}\")\n",
        "\n",
        "# Initialize a new vector store for storing successful Q&A pairs\n",
        "def initialize_qa_vector_store():\n",
        "    create_successful_qa_table()  # Ensure the table exists with the correct schema\n",
        "    return BigQueryVectorStore(\n",
        "        project_id=project,\n",
        "        dataset_name=dataset,\n",
        "        table_name=\"successful_qa_pairs\",\n",
        "        location=location,\n",
        "        embedding=embedding_model,\n",
        "        text_column=\"content\",\n",
        "        embedding_column=\"embedding\",\n",
        "        id_column=\"id\"\n",
        "    )\n",
        "\n",
        "qa_vector_store = initialize_qa_vector_store()\n",
        "\n",
        "def load_vector_storage():\n",
        "    query = f\"\"\"\n",
        "    SELECT date_month as month, COALESCE(report_analysis, '') || COALESCE(invoice_analysis, '') || COALESCE(recurring_payments_analysis, '') as content\n",
        "    FROM `{project}.{dataset}.pl_reports`\n",
        "    \"\"\"\n",
        "    df = client.query(query).to_dataframe()\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        month = row['month']\n",
        "        text = row['content']\n",
        "        metadata = {'month': month}  # Removed analysis_type as it's no longer needed\n",
        "        vector_store.add_texts([text], metadatas=[metadata])\n",
        "\n",
        "    print(\"Vector storage loaded successfully.\")\n",
        "\n",
        "def get_available_months():\n",
        "    query = f\"\"\"\n",
        "    SELECT DISTINCT month as month\n",
        "    FROM `{project}.{dataset}.pl_reports_vector_storage`\n",
        "    ORDER BY month DESC\n",
        "    \"\"\"\n",
        "    df = client.query(query).to_dataframe()\n",
        "    return df['month'].tolist()\n",
        "\n",
        "# Add this function to determine the valid time range\n",
        "def get_valid_time_range(available_months):\n",
        "    if not available_months:\n",
        "        return None, None\n",
        "\n",
        "    latest_month = max(available_months)\n",
        "    earliest_month = min(available_months)\n",
        "\n",
        "    # Calculate the start of the year for the latest month\n",
        "    year_start = latest_month.replace(month=1, day=1)\n",
        "\n",
        "    # The valid range includes two months before the earliest available month\n",
        "    valid_start = (earliest_month - relativedelta(months=2)).replace(day=1)\n",
        "\n",
        "    return valid_start, latest_month\n",
        "\n",
        "def create_lookup_tables():\n",
        "    query = f\"\"\"\n",
        "    SELECT DISTINCT\n",
        "        account_report_group,\n",
        "        account_report_sub_category,\n",
        "        account_category\n",
        "    FROM `{project}.{dataset}.profit_and_loss_report_account_group`\n",
        "    \"\"\"\n",
        "    df = client.query(query).to_dataframe()\n",
        "\n",
        "    lookups = {\n",
        "        'group': defaultdict(list),\n",
        "        'sub_category': defaultdict(list),\n",
        "        'category': defaultdict(list)\n",
        "    }\n",
        "\n",
        "    for _, row in df.iterrows():\n",
        "        group = row['account_report_group']\n",
        "        sub_category = row['account_report_sub_category']\n",
        "        category = row['account_category']\n",
        "\n",
        "        lookups['group'][group.lower()].append(group)\n",
        "        lookups['sub_category'][sub_category.lower()].append(sub_category)\n",
        "        lookups['category'][category.lower()].append(category)\n",
        "\n",
        "    return lookups\n",
        "\n",
        "lookups = create_lookup_tables()\n",
        "\n",
        "memory = ConversationBufferMemory()\n",
        "db = SQLDatabase.from_uri(sqlalchemy_url)\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-4\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        ")\n",
        "conversation_chain = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=memory\n",
        ")\n",
        "toolkit = SQLDatabaseToolkit(db=db, llm=llm)\n",
        "agent_executor = create_sql_agent(\n",
        "    llm=llm,\n",
        "    toolkit=toolkit,\n",
        "    verbose=True,\n",
        "    top_k=1000,\n",
        ")\n",
        "\n",
        "def find_matching_values(question, lookups):\n",
        "    words = question.lower().split()\n",
        "    matches = {\n",
        "        'group': set(),\n",
        "        'sub_category': set(),\n",
        "        'category': set()\n",
        "    }\n",
        "\n",
        "    for word in words:\n",
        "        for key in lookups:\n",
        "            if word in lookups[key]:\n",
        "                matches[key].update(lookups[key][word])\n",
        "\n",
        "    return matches\n",
        "\n",
        "def construct_filter_clause(matches):\n",
        "    clauses = []\n",
        "    for key, values in matches.items():\n",
        "        if values:\n",
        "            column = \"account_report_group\" if key == \"group\" else f\"account_{key}\"\n",
        "            quoted_values = [\"'{0}'\".format(v) for v in values]\n",
        "            clause = \"{0} IN ({1})\".format(column, \", \".join(quoted_values))\n",
        "            clauses.append(clause)\n",
        "\n",
        "    return \" AND \".join(clauses) if clauses else \"\"\n",
        "\n",
        "def determine_view(matches):\n",
        "    if matches['group']:\n",
        "        return \"profit_and_loss_report_account_group_xa\"\n",
        "    elif matches['sub_category']:\n",
        "        return \"profit_and_loss_report_sub_categories_xa\"\n",
        "    else:\n",
        "        return \"profit_and_loss_report_categories_xa\"\n",
        "\n",
        "def extract_time_periods(question):\n",
        "    \"\"\"Extract time periods mentioned in the question.\"\"\"\n",
        "    # Patterns for various time formats\n",
        "    year_pattern = r'\\b(20\\d{2})\\b'\n",
        "    month_year_pattern = r'\\b(Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\\s+(\\d{4})\\b'\n",
        "    quarter_pattern = r'\\b(Q[1-4])\\s+(\\d{4})\\b'\n",
        "\n",
        "    time_periods = []\n",
        "\n",
        "    # Extract years\n",
        "    years = re.findall(year_pattern, question)\n",
        "    for year in years:\n",
        "        time_periods.append(('year', int(year)))\n",
        "\n",
        "    # Extract month-year combinations\n",
        "    month_years = re.findall(month_year_pattern, question, re.IGNORECASE)\n",
        "    for month, year in month_years:\n",
        "        date = parser.parse(f\"{month} {year}\")\n",
        "        time_periods.append(('month', date))\n",
        "\n",
        "    # Extract quarters\n",
        "    quarters = re.findall(quarter_pattern, question)\n",
        "    for quarter, year in quarters:\n",
        "        quarter_num = int(quarter[1])\n",
        "        start_month = (quarter_num - 1) * 3 + 1\n",
        "        time_periods.append(('quarter', parser.parse(f\"{year}-{start_month:02d}-01\")))\n",
        "\n",
        "    return time_periods\n",
        "\n",
        "def strip_html(html_content):\n",
        "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
        "    return soup.get_text()\n",
        "\n",
        "def summarize_content(question, content):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"content\"],\n",
        "        template=\"\"\"Given the following question and content, provide a concise summary of the content that is directly relevant to answering the question.\n",
        "        Ignore any information that doesn't pertain to the question. All amounts should be stated in GBP (£).\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Content: {content}\n",
        "\n",
        "        Relevant Summary:\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    summary = chain.run(question=question, content=content)\n",
        "    return summary.strip()\n",
        "\n",
        "def should_query_vector_store(question):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"content_description\", \"valid_time_range\"],\n",
        "        template=\"\"\"Given the following question and description of the content in a vector store,\n",
        "        determine if the vector store is likely to contain information that can answer the question.\n",
        "        Consider the following:\n",
        "        1. Does the question ask about any of the key metrics or analyses mentioned in the content description?\n",
        "        2. Does the question fall within the time frame covered by the vector store? Valid time range: {valid_time_range}\n",
        "        3. Is the level of detail requested (category, subcategory, account group) available in the vector store?\n",
        "\n",
        "        Respond with 'Yes' if the vector store is likely to contain relevant information, or 'No' if it's unlikely or unclear.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Vector Store Content Description:\n",
        "        {content_description}\n",
        "\n",
        "        Decision (Yes/No):\n",
        "        Explanation:\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    response = chain.run(question=question,\n",
        "                         content_description=vector_store_content_description,\n",
        "                         valid_time_range=f\"{valid_time_range[0].strftime('%B %Y')} to {valid_time_range[1].strftime('%B %Y')}\")\n",
        "\n",
        "\n",
        "    # Extract the decision from the response\n",
        "    decision_match = re.search(r'Decision \\(Yes/No\\):\\s*(Yes|No)', response, re.IGNORECASE)\n",
        "    if decision_match:\n",
        "        decision = decision_match.group(1).lower()\n",
        "        return decision == 'yes'\n",
        "    else:\n",
        "        # If no clear decision is found in the expected format, look for a 'Yes' at the beginning of the response\n",
        "        if response.strip().lower().startswith('yes'):\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "def evaluate_answer_relevance(question, answer):\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=[\"question\", \"answer\"],\n",
        "        template=\"\"\"Given the following question and answer, evaluate how well the answer addresses the question.\n",
        "        Provide a relevance score as a percentage and a brief explanation.\n",
        "\n",
        "        Question: {question}\n",
        "\n",
        "        Answer: {answer}\n",
        "\n",
        "        Relevance Score (0-100%):\n",
        "        Explanation:\"\"\"\n",
        "    )\n",
        "\n",
        "    chain = LLMChain(llm=llm, prompt=prompt)\n",
        "    response = chain.run(question=question, answer=answer)\n",
        "    return response\n",
        "\n",
        "def ask_question(question, context=\"\"):\n",
        "    time_periods = extract_time_periods(question)\n",
        "\n",
        "    if should_query_vector_store(question):\n",
        "        month = time_periods[0][1] if time_periods and time_periods[0][0] in ['month', 'quarter'] else None\n",
        "        filter_dict = {\"month\": month.strftime('%Y-%m-%d') if month else None}\n",
        "\n",
        "        if filter_dict[\"month\"] is None: # Check for None before passing\n",
        "            relevant_docs = vector_store.similarity_search(question, k=1) # Remove the filter\n",
        "        else:\n",
        "            relevant_docs = vector_store.similarity_search(question, k=1, filter=filter_dict)\n",
        "\n",
        "        if relevant_docs:\n",
        "            pre_created_answer = relevant_docs[0].page_content\n",
        "            stripped_answer = strip_html(pre_created_answer)\n",
        "            summarized_answer = summarize_content(question, stripped_answer)\n",
        "            answer = f\"Based on the pre-created analysis: {summarized_answer}\"\n",
        "        else:\n",
        "            answer = \"No relevant pre-created analysis found. Falling back to SQL query.\"\n",
        "    else:\n",
        "        answer = \"The question cannot be answered by pre-created analysis. Using SQL query.\"\n",
        "\n",
        "    if \"Using SQL query\" in answer:\n",
        "        matches = find_matching_values(question, lookups)\n",
        "        filter_clause = construct_filter_clause(matches)\n",
        "        view_name = determine_view(matches)\n",
        "\n",
        "        date_filter = construct_date_filter(time_periods)\n",
        "\n",
        "        if date_filter:\n",
        "            if filter_clause: # Add AND only if there's an existing filter clause\n",
        "                filter_clause = f\"{filter_clause} AND {date_filter}\"\n",
        "            else:\n",
        "                filter_clause = date_filter\n",
        "\n",
        "        instruction = f\"\"\"You are a knowledgeable finance data analyst working for Rittman Analytics.\n",
        "        Use the `{project}.{dataset}.{view_name}` view to answer this question.\n",
        "        Use the following SQL filter clause in your query: {filter_clause}\n",
        "        When calculating revenue or any other financial metrics, make sure to aggregate the values for the entire time period(s) mentioned in the question (which may be months, quarters, or years).\n",
        "        If no specific time period is mentioned, provide an overview of all available data.\n",
        "        If multiple time periods are mentioned, provide a comparison between them.\n",
        "        Please construct and execute a SQL query to answer the question, making sure to include the filter clause.\n",
        "        Do not include markdown-style triple backticks in the SQL you generate and try to use or validate.\n",
        "\n",
        "        {context}\n",
        "\n",
        "        Question is: {question}\n",
        "        \"\"\"\n",
        "\n",
        "        answer = agent_executor.run(instruction)\n",
        "\n",
        "    relevance_evaluation = evaluate_answer_relevance(question, answer)\n",
        "\n",
        "    return f\"{answer}\\n\\nRelevance Evaluation:\\n{relevance_evaluation}\"\n",
        "\n",
        "def construct_date_filter(time_periods):\n",
        "    \"\"\"Construct a SQL date filter based on extracted time periods using AND for multiple periods.\"\"\"\n",
        "    filters = []\n",
        "    for period_type, date in time_periods:\n",
        "        if period_type == 'year':\n",
        "            filters.append(f\"EXTRACT(YEAR FROM date_month) = {date}\")\n",
        "        elif period_type == 'month':\n",
        "            filters.append(f\"EXTRACT(MONTH FROM date_month) = {date.month} AND EXTRACT(YEAR FROM date_month) = {date.year}\")\n",
        "        elif period_type == 'quarter':\n",
        "            quarter_start = date\n",
        "            quarter_end = date + relativedelta(months=2, day=calendar.monthrange(date.year, date.month + 2)[1]) #Correctly calculate end of quarter\n",
        "            filters.append(f\"date_month BETWEEN DATE('{quarter_start.strftime('%Y-%m-%d')}') AND DATE('{quarter_end.strftime('%Y-%m-%d')}')\")\n",
        "\n",
        "    return \" AND \".join(filters) if filters else \"\"\n",
        "\n",
        "def extract_dates_from_question(question):\n",
        "    \"\"\"Extract all years mentioned in the question.\"\"\"\n",
        "    year_pattern = r'\\b(20\\d{2})\\b'\n",
        "    return list(set(re.findall(year_pattern, question)))\n",
        "\n",
        "def get_similar_qa(question: str, k: int = 3):\n",
        "    \"\"\"Retrieve similar Q&A pairs from the vector store.\"\"\"\n",
        "    print(f\"Searching for similar Q&A pairs to: {question}\")\n",
        "    similar_qa = qa_vector_store.similarity_search(question, k=k)\n",
        "    print(f\"Retrieved {len(similar_qa)} similar Q&A pairs\")\n",
        "\n",
        "    converted_results = []\n",
        "    for i, item in enumerate(similar_qa):\n",
        "        if isinstance(item, Document):\n",
        "            converted_results.append(item)\n",
        "            print(f\"Document {i+1} (already Document):\")\n",
        "            print(f\"  Page content: {item.page_content[:100]}...\")\n",
        "            print(f\"  Metadata: {item.metadata}\")\n",
        "        else:\n",
        "            # Handle cases where the item might be a dict or have a different structure\n",
        "            text = item.get('text', item.get('page_content', ''))\n",
        "            metadata = {key: value for key, value in item.items() if key not in ['text', 'page_content']}\n",
        "            doc = Document(page_content=text, metadata=metadata)\n",
        "            converted_results.append(doc)\n",
        "            print(f\"Document {i+1} (converted to Document):\")\n",
        "            print(f\"  Page content: {text[:100]}...\")\n",
        "            print(f\"  Metadata: {metadata}\")\n",
        "\n",
        "    return converted_results\n",
        "\n",
        "def format_similar_qa(similar_qa):\n",
        "    \"\"\"Format similar Q&A pairs for inclusion in the prompt.\"\"\"\n",
        "    formatted = \"Similar Q&A pairs from past interactions:\\n\\n\"\n",
        "    for i, doc in enumerate(similar_qa, 1):\n",
        "        formatted += f\"{i}. {doc.page_content}\\n\\n\"\n",
        "    return formatted\n",
        "\n",
        "def ask_question_with_feedback_and_learning(question: str, max_iterations: int = 3) -> str:\n",
        "    iteration = 0\n",
        "    while iteration < max_iterations:\n",
        "        # Retrieve similar Q&A pairs\n",
        "        similar_qa = get_similar_qa(question)\n",
        "\n",
        "        # Prepare the context with similar Q&A pairs\n",
        "        context = format_similar_qa(similar_qa)\n",
        "\n",
        "        # Use the modified ask_question function with context\n",
        "        answer = ask_question(question, context)\n",
        "        print(f\"\\nAnswer (Iteration {iteration + 1}):\\n{answer}\")\n",
        "\n",
        "        user_satisfied = input(\"\\nDid this answer your question sufficiently? (yes/no): \").lower().strip()\n",
        "\n",
        "        if user_satisfied == 'yes':\n",
        "            # Store the successful Q&A pair\n",
        "            store_successful_qa(question, answer)\n",
        "            return answer\n",
        "\n",
        "        feedback = input(\"Please provide feedback on how the answer could be improved: \")\n",
        "\n",
        "        # Use LLM to analyze feedback and improve the question\n",
        "        improve_prompt = PromptTemplate(\n",
        "            input_variables=[\"original_question\", \"answer\", \"feedback\", \"context\"],\n",
        "            template=\"\"\"Given the original question, the provided answer, user feedback, and similar Q&A pairs from past interactions,\n",
        "            please suggest an improved version of the question that addresses the user's concerns.\n",
        "\n",
        "            Original Question: {original_question}\n",
        "\n",
        "            Provided Answer: {answer}\n",
        "\n",
        "            User Feedback: {feedback}\n",
        "\n",
        "            {context}\n",
        "\n",
        "            Improved Question:\"\"\"\n",
        "        )\n",
        "\n",
        "        improve_chain = LLMChain(llm=llm, prompt=improve_prompt)\n",
        "        improved_question = improve_chain.run(\n",
        "            original_question=question,\n",
        "            answer=answer,\n",
        "            feedback=feedback,\n",
        "            context=context\n",
        "        )\n",
        "\n",
        "        print(f\"\\nImproved question based on feedback: {improved_question}\")\n",
        "\n",
        "        question = improved_question  # Update the question for the next iteration\n",
        "        iteration += 1\n",
        "\n",
        "    return \"I apologize, but I couldn't provide a satisfactory answer within the maximum number of iterations. Please try rephrasing your question or contact support for further assistance.\"\n",
        "\n",
        "\n",
        "def store_successful_qa(question: str, answer: str):\n",
        "    \"\"\"Store a successful question-answer pair in the vector store.\"\"\"\n",
        "    qa_pair = f\"Q: {question}\\nA: {answer}\"\n",
        "\n",
        "    # Generate embedding for the QA pair\n",
        "    embedded_vector = embedding_model.embed_query(qa_pair)\n",
        "\n",
        "    # Prepare the row to be inserted\n",
        "    row = {\n",
        "        'content': qa_pair,\n",
        "        'embedding': embedded_vector,\n",
        "        'id': str(uuid.uuid4())  # Generate a unique ID\n",
        "    }\n",
        "\n",
        "    # Insert the row into BigQuery\n",
        "    client = bigquery.Client()\n",
        "    table_id = f\"{project}.{dataset}.successful_qa_pairs\"\n",
        "\n",
        "    # Insert the row into BigQuery\n",
        "    errors = client.insert_rows_json(table_id, [row]) # Use correctly defined table_id\n",
        "\n",
        "    if errors == []:\n",
        "        print(\"Successful Q&A pair stored in vector store.\")\n",
        "    else:\n",
        "        print(f\"Errors occurred while storing Q&A pair: {errors}\")\n",
        "\n",
        "\n",
        "\n",
        "def main(reload_vector_storage=False):\n",
        "    global valid_time_range, vector_store_content_description\n",
        "\n",
        "    if reload_vector_storage:\n",
        "        load_vector_storage()\n",
        "\n",
        "    available_months = get_available_months()\n",
        "    valid_time_range = get_valid_time_range(available_months)\n",
        "\n",
        "    # Update the vector_store_content_description with the actual time range\n",
        "    vector_store_content_description += f\"\"\"\n",
        "    The analysis covers the period from {valid_time_range[0].strftime('%B %Y')} to {valid_time_range[1].strftime('%B %Y')}.\n",
        "    For each month in this range, the analysis includes data for that month, comparisons to the two previous months, and year-to-date figures.\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"Hi! Ask me a question about our company's profit and loss data\")\n",
        "    while True:\n",
        "        question = input(\"\\nYour question (or type 'QUIT' to exit): \")\n",
        "        if question.lower() == 'quit':\n",
        "            break\n",
        "\n",
        "        final_answer = ask_question_with_feedback_and_learning(question)\n",
        "        print(f\"\\nFinal Answer: {final_answer}\")\n",
        "        print(\"\\n---\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main(reload_vector_storage=false)  # Set to True to reload vector storage"
      ],
      "metadata": {
        "id": "MeWPaAlSWrvj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}